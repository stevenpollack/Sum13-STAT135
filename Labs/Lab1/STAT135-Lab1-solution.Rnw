\documentclass[12pt]{article}

\usepackage{amsmath,amssymb,fancyhdr,palatino}
\usepackage[textheight=8in,textwidth=6.5in]{geometry}

%%%%% knitr code to make sure things stay inside listings box:
\usepackage{listings}
\usepackage{inconsolata}

% # <<stayInside,eval=FALSE,echo=FALSE>>=
% #   options(width=60)
% # 
% #   listing <- function(x, options) {
% #     paste("\\begin{lstlisting}[basicstyle=\\ttfamily,breaklines=true]\n",
% #           x,"\\end{lstlisting}\n", sep = "")
% #   }
% #   knit_hooks$set(source=listing, output=listing)
% # @
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\lhead{STAT 135}
\chead{Lab \#1 -- Sample Report}
\rhead{Survey Sampling}
\cfoot{\thepage}

\newcommand{\R}{\texttt{R}}
\newcommand{\N}{\ensuremath{\mathcal{N}}}

\DeclareMathOperator{\var}{var}

\title{STAT 135 \\ Lab Assignment \#1}
\author{Sample Report}
\date{}

\begin{document}
\maketitle
\pagestyle{fancy}

<<globalParameters,echo=FALSE>>=
set.seed(1234)
opts_chunk$set(comment=NA,tidy=F,warning=FALSE,message=FALSE)
@

\section{Introduction:} In John Rice's textbook, \textit{Mathematical Statistics and Data Analysis}, a guideline for central limit theorem-type behaviour is described for simple random samples. The guideline is, 

\begin{quote}
... if [the sample size] is large, but still small relative to [the population size], then $\overline{X}_n$, the mean of a simple random sample, is approximately normally distributed.
\end{quote}

However, this guideline leaves much to be interpreted. For instance, how ``small'' can the ratio of sample size : population size be, before it is too big? This report outlines a simulation study performed on two data sets (one artificial, and one real) which surveys acceptable ranges for the size of this ratio.

<<setup,eval=TRUE>>=
set.seed(1234)
N <- 1000 
sample.sizes <- c(12,400,800)

# an alpha-% CI needs to be calculated with level=(1-alpha)
alpha <- 1-0.5325

artificial.data <- rchisq(n=N, df=4)
moms.data <- read.table(file="../../Past_Labs/data/1000moms.txt", header=T)
real.data <- moms.data[,2] # choose to work with "numkids"
@

\section{Methodology:} Since the real-life data set (taken to be the \texttt{numkids} column in the file, \texttt{1000moms.txt}) had 1000 entries, a population of 1000 randomly generated $\chi^2_{4}$ random variables was created as an artificial analogue to this set. To determine how big or small the ratio of sample size to population size should be, before the sampling distribution of the mean stops being well-approximated by a Gaussian random variable, three sample sizes were chosen: $n = \Sexpr{paste(sample.sizes,collapse=",")}$. Within each sample size, and for each data set, the sampling distribution of the mean was estimated (through 10000 replications), and its standardized distribution was compared in a Q-Q plot to that of a standard normal. Atop of that, approximate 53.25\% confidence intervals were calculated, assuming the central limit theorem, and their true coverage was determined. The code for the calculations is provided in the Appendix, and the resulting figures and statistics can be found in the Results section.

<<simulationCode,eval=T,fig.keep='all',echo=FALSE>>=
### program outline:
### 1. create function to calculate alpha-% CI from a sample
### 2. automate sampling and stat calculation step
### 3. replicate step 2
### 4. repeat steps 2 and 3 for all sample sizes

alphaLevelConfidenceInterval <- function(sample,alpha) {
  z <- qnorm(p=alpha/2, lower.tail=F)
  X.bar <- mean(sample)
  n <- length(sample)
  s2 <- (N-n)/(n*(n-1)*N) * sum((sample - X.bar)^2)
  return( X.bar + c(-1,1)*z*sqrt(s2) )
}

collectSampleAndCalculateStats <- function(sample.size,population,alpha) {
  ### automates sampling from population for a given
  ### sample.size and population. Then, calculates
  ### sample mean and alpha-% CI using central limit
  ### theorem...
  ### output is a vector of length=3:
  ### output[1] = sample mean
  ### output[2:3] = calculated CI
  
  rndm.sample <- sample(x=population,size=sample.size,replace=F)
  sample.mean <- mean(rndm.sample)
  sample.CI <- alphaLevelConfidenceInterval(rndm.sample,alpha)
  return(c(sample.mean, sample.CI))
}

replicateSamplingProcedure <- function(sample.size, population, alpha) {
  ### just a fancy wrapper for R's replicate function
  ### use a replication factor of n=100 to estimate
  ### sampling distribution
  replicate(n=10000,
            expr={
              collectSampleAndCalculateStats(sample.size,
                                             population,
                                             alpha)
              })  
}

analyzeReplicates <- function(replicates, mu, sample.size) {
  ### this function takes the output of 
  ### replicateSamplingProcedure (3x100 matrix)
  ### and 
  ### 1. checks which of the 100 CI's actually
  ###    contain mu
  ### 2. produces histograms and Q-Q plots of 
  ###    sampling distribution
  ### Note that input parameter mu is assumed
  ### to be population mean
  ###
  ### For thoroughness, function returns
  ### both graphics objects, and the coverage
  
  require(ggplot2) # load ggplot2 package
  
  prop <- apply(X=replicates, MARGIN=2, FUN=function(col){ as.numeric(col[2] <= mu && mu <= col[3]) })
  
  analysis.df <- data.frame(sample.mean=replicates[1,], lwr=replicates[2,], upr=replicates[3,], is.mu.covered=prop)
  
  hist.obj <- ggplot(data=analysis.df) + geom_histogram(aes(x=sample.mean)) + geom_vline(aes(xintercept=mean(sample.mean)), colour='blue',alpha=0.5,size=1) + geom_vline(xintercept=mu,colour='red',alpha=0.5,size=1) + labs(list(title=paste("Histogram of sampling distribution when n =", sample.size, "\n Red line indicates true mean \n Blue line indicates distributional mean"), x="Sample mean"))
  
#   with(analysis.df, {hist(sample.mean, main=)
#         
#   abline(v=c(mu,mean(sample.mean)),col=c('red','green'))})
  
  analysis.df <- transform(analysis.df,std.sample.mean=(sample.mean-mean(sample.mean))/sd(sample.mean))
  
  qqplot.obj <- ggplot(data=analysis.df) + stat_qq(aes(sample=std.sample.mean)) + geom_abline(slope=1,intercept=0,colour='red') + labs(title=paste("Q-Q plot of standardized sampling distribution against standard normal \n with n =", sample.size))
        
#   qqnorm(std.sample.mean, main=)
#   abline(a=0,b=1,col="red")

  return(list(hist=hist.obj,qqplot=qqplot.obj,coverage=mean(prop)))
}

runSimulation <- function(sample.sizes, population, alpha) {
  ### simple wrapper putting all of our
  ### helper functions together;
  ### It will produce the analysis for each value in
  ### sample.sizes and output coverages
  lapply(X=sample.sizes,
                FUN=function(sample.size, pop){
  replicates <- replicateSamplingProcedure(sample.size,pop,alpha)
  analyzeReplicates(replicates,mean(pop),sample.size)
},
                pop=population)
}

artificial.data.results <- runSimulation(sample.sizes, artificial.data, alpha)
real.data.results <- runSimulation(sample.sizes, real.data, alpha)

coverage.analysis <- data.frame(sample.sizes)
coverage.analysis <- within(coverage.analysis,expr={
  artificial.coverages <- unlist(lapply(X=artificial.data.results,FUN=function(results){results$coverage}))
  real.data.coverages <- unlist(lapply(X=real.data.results,FUN=function(results){results$coverage}))
})
@

\section{Results:}

Figures 1, 2 and 3 display the histograms and Q-Q plots for the sampling distribution of $\overline{X}_n$, when the sampling from the artificial data set, and varying the sample size between $n= \Sexpr{paste(sample.sizes,collapse=",")}$. Similarly, figures 4, 5 and 6 display the histograms when sampling from the \texttt{numkids} column in the \texttt{1000moms.txt} data set. Finally, table 1 displays the coverage probabilities for our approximate confidence intervals.


<<artificialData1,dev='pdf',fig.align='center',fig.show='hold',out.width="0.47\\textwidth",fig.cap=paste("Histogram and Q-Q plot for sampling distribution of $\\overline{X}_n$, on artificial data set when $n$ =", sample.sizes[1]),echo=FALSE,fig.pos="ht!",results='hide'>>=
artificial.data.results[[1]]
@

<<artificialData2,dev='pdf',fig.align='center',fig.show='hold',out.width="0.47\\textwidth",fig.cap=paste("Histogram and Q-Q plot for sampling distribution of $\\overline{X}_n$, on artificial data set when $n$ =", sample.sizes[2]),echo=FALSE,fig.pos="ht!",results='hide'>>=
artificial.data.results[[2]]
@

<<artificialData3,dev='pdf',fig.align='center',fig.show='hold',out.width="0.47\\textwidth",fig.cap=paste("Histogram and Q-Q plot for sampling distribution of $\\overline{X}_n$, on artificial data set when $n$ =", sample.sizes[3]),echo=FALSE,fig.pos="ht!",results='hide'>>=
artificial.data.results[[3]]
@

<<realData1,dev='pdf',fig.align='center',fig.show='hold',out.width="0.47\\textwidth",fig.cap=paste("Histogram and Q-Q plot for sampling distribution of $\\overline{X}_n$, on real-life data set when $n$ =", sample.sizes[1]),echo=FALSE,fig.pos="ht!",results='hide'>>=
real.data.results[[1]]
@

<<realData2,dev='pdf',fig.align='center',fig.show='hold',out.width="0.47\\textwidth",fig.cap=paste("Histogram and Q-Q plot for sampling distribution of $\\overline{X}_n$, on real-life data set when $n$ =", sample.sizes[2]),echo=FALSE,fig.pos="ht!",results='hide'>>=
real.data.results[[2]]
@

<<realData3,dev='pdf',fig.align='center',fig.show='hold',out.width="0.47\\textwidth",fig.cap=paste("Histogram and Q-Q plot for sampling distribution of $\\overline{X}_n$, on real-life data set when $n$ =", sample.sizes[3]),echo=FALSE,fig.pos="ht!",results='hide'>>=
real.data.results[[3]]
@

<<coverageTable,echo=FALSE,results='asis'>>=
library(xtable)
colnames(coverage.analysis) <- c("Sample Size", "Coverage for Real Data", "Coverage for Artificial Data")
print(xtable(coverage.analysis,digits=c(2,0,4,4),caption="Coverage of confidence intervals for the various sample sizes.",align="|l|c|c|c|"),include.rownames=F)
@

Off the bat, the plots in figure 1 show us that for $n=\Sexpr{sample.sizes[1]}$ we shouldn't expect good coverage from our normal-based confidence intervals, the right tail of this distribution are looks fatter than it should be. Quantitatively, the coverage was measured at \Sexpr{artificial.data.results[[1]]$coverage * 100}\% which is nowhere near what we expected. Conversely, the small sample coverage with the real data set, measured at \Sexpr{real.data.results[[1]]$coverage * 100}\%, something that's more acceptable. 

In general, the distributions for the sample sizes seem to approach something well-approximated by a Normal random variable, as we can see with the coverage probabilities approaching the target 53.25\%. In particular, the largest sample size yielded confidence intervals that had coverage within \Sexpr{max(abs(0.5325 - coverage.analysis[3,2:3]))*100}\% of the target coverage. However, the middle sample size, $n=\Sexpr{sample.sizes[2]}$, yielded very good normal-based confidence intervals on the artifical data.

\section{Conclusion:} Though more investigation could be performed, this shallow study has revealed that letting the sample size get as large as 80\% (and as small as 1.2\%) the population size can yield sampling distributions that are well-approximated with a normal random variable. For artificial data, a bit of caution should be employed when taking samples that are as small as the 1.2\% threshold, here; however, inside the real data set, the smallest sample size had coverage that wasn't more than \Sexpr{abs(0.5325 - coverage.analysis[1,2])*100}\% from our target (which may, or may not be acceptable for certain investigators).

All in all, it seems that there's a great deal in flexibility regarding how large a simple random sample needs to be, relative to the population size, inorder to perform reasonable inference with normal-based approximations.

\section{Appendix:} Code to be released after due date.
<<stayInside,echo=FALSE>>=
  options(width=60)
  listing <- function(x, options) {
     paste("\\begin{lstlisting}[basicstyle=\\ttfamily,breaklines=true]\n", x,"\\end{lstlisting}\n", sep = "")
  }
  
  knit_hooks$set(source=listing, output=listing)
@

%<<refChunk,ref.label="simulationCode",eval=FALSE,highlight=F>>=
%@
\end{document}

<<echo=FALSE,eval=FALSE>>=

########################
# out.df <- data.frame(X=1:length(out[1,]), LB=out[2,], UB=out[3,])
# out.df <- transform(out.df, Y=(UB+LB)/2)
# 
# ggplot() + geom_linerange(data=out.df, aes(x=X,ymin=LB,ymax=UB,y=Y)) + geom_hline(yintercept=5)

@
